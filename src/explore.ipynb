{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here\n",
                "\n",
                "It's recommended to use this notebook for exploration purposes.\n",
                "\n",
                "For example: \n",
                "\n",
                "1. You could import the CSV generated by python into your notebook and explore it.\n",
                "2. You could connect to your database using `pandas.read_sql` from this notebook and explore it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting pandas\n",
                        "  Downloading pandas-1.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
                        "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
                        "\u001b[?25hCollecting numpy>=1.18.5\n",
                        "  Using cached numpy-1.23.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
                        "Collecting pytz>=2020.1\n",
                        "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
                        "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
                        "Installing collected packages: pytz, numpy, pandas\n",
                        "Successfully installed numpy-1.23.1 pandas-1.4.3 pytz-2022.1\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Collecting regex\n",
                        "  Downloading regex-2022.7.24-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (768 kB)\n",
                        "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.2/768.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: regex\n",
                        "Successfully installed regex-2022.7.24\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Collecting matplotlib\n",
                        "  Using cached matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
                        "Requirement already satisfied: numpy>=1.17 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (1.23.1)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
                        "Collecting kiwisolver>=1.0.1\n",
                        "  Using cached kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
                        "Collecting cycler>=0.10\n",
                        "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
                        "Requirement already satisfied: python-dateutil>=2.7 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
                        "Requirement already satisfied: pyparsing>=2.2.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
                        "Collecting fonttools>=4.22.0\n",
                        "  Using cached fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
                        "Collecting pillow>=6.2.0\n",
                        "  Using cached Pillow-9.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.2 MB)\n",
                        "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
                        "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
                        "Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.4 matplotlib-3.5.2 pillow-9.2.0\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Collecting nltk\n",
                        "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
                        "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nltk) (2022.7.24)\n",
                        "Collecting joblib\n",
                        "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
                        "Collecting click\n",
                        "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
                        "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting tqdm\n",
                        "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
                        "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: tqdm, joblib, click, nltk\n",
                        "Successfully installed click-8.1.3 joblib-1.1.0 nltk-3.7 tqdm-4.64.0\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "! pip install pandas\n",
                "! pip install regex\n",
                "! pip install matplotlib\n",
                "! pip install nltk\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting sklearn\n",
                        "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
                        "Collecting scikit-learn\n",
                        "  Using cached scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
                        "Collecting threadpoolctl>=2.0.0\n",
                        "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
                        "Collecting scipy>=1.3.2\n",
                        "  Using cached scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
                        "Requirement already satisfied: numpy>=1.17.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.23.1)\n",
                        "Requirement already satisfied: joblib>=1.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
                        "Installing collected packages: threadpoolctl, scipy, scikit-learn, sklearn\n",
                        "Successfully installed scikit-learn-1.1.1 scipy-1.8.1 sklearn-0.0 threadpoolctl-3.1.0\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "! pip install sklearn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import pandas as pd \n",
                "import regex as reg\n",
                "import re\n",
                "import matplotlib.pyplot as plt\n",
                "import unicodedata\n",
                "import nltk\n",
                "import string\n",
                "import pickle\n",
                "\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "\n",
                "from sklearn import model_selection, svm\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "from nltk.corpus import stopwords\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_raw = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<bound method DataFrame.info of                                                     url  is_spam\n",
                            "0     https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                                https://www.hvper.com/     True\n",
                            "2                    https://briefingday.com/m/v4n3i4f3     True\n",
                            "3      https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                           https://briefingday.com/fan     True\n",
                            "...                                                 ...      ...\n",
                            "2994  https://www.smartcitiesworld.net/news/news/dee...    False\n",
                            "2995                      https://www.youtube.com/watch     True\n",
                            "2996  https://techcrunch.com/2019/07/04/an-optimisti...    False\n",
                            "2997  https://www.technologyreview.com/2019/12/20/13...    False\n",
                            "2998       https://www.bbc.com/news/technology-51018758    False\n",
                            "\n",
                            "[2999 rows x 2 columns]>"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw.info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Vamos a pasar a 0 y 1 la variable objetivo\n",
                "\n",
                "df_raw['is_spam'] = df_raw['is_spam'].apply(lambda x: 1 if x == True else 0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<bound method DataFrame.info of                                                     url  is_spam\n",
                            "0     https://briefingday.us8.list-manage.com/unsubs...        1\n",
                            "1                                https://www.hvper.com/        1\n",
                            "2                    https://briefingday.com/m/v4n3i4f3        1\n",
                            "3      https://briefingday.com/n/20200618/m#commentform        0\n",
                            "4                           https://briefingday.com/fan        1\n",
                            "...                                                 ...      ...\n",
                            "2994  https://www.smartcitiesworld.net/news/news/dee...        0\n",
                            "2995                      https://www.youtube.com/watch        1\n",
                            "2996  https://techcrunch.com/2019/07/04/an-optimisti...        0\n",
                            "2997  https://www.technologyreview.com/2019/12/20/13...        0\n",
                            "2998       https://www.bbc.com/news/technology-51018758        0\n",
                            "\n",
                            "[2999 rows x 2 columns]>"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw.info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 2999 entries, 0 to 2998\n",
                        "Data columns (total 2 columns):\n",
                        " #   Column   Non-Null Count  Dtype \n",
                        "---  ------   --------------  ----- \n",
                        " 0   url      2999 non-null   object\n",
                        " 1   is_spam  2999 non-null   int64 \n",
                        "dtypes: int64(1), object(1)\n",
                        "memory usage: 47.0+ KB\n"
                    ]
                }
            ],
            "source": [
                "df_raw.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "2109                            http://elv.fnd.to/crownes\n",
                            "2587                  https://deceuvel.nl/en/organisatie/\n",
                            "1226    https://www.vox.com/2020/6/22/21293168/dc-stat...\n",
                            "2797    https://www.reddit.com/r/aww/comments/hiz3bh/s...\n",
                            "1978    https://www.penguinrandomhouse.com/books/57678...\n",
                            "1195                   https://www.stophateforprofit.org/\n",
                            "2623    https://www.morningbrew.com/daily/stories/2020...\n",
                            "1419    https://www.theringer.com/2020/6/18/21294510/b...\n",
                            "2562    https://abcnews.go.com/US/george-floyds-relati...\n",
                            "2505    https://docs.google.com/forms/d/e/1FAIpQLSdkbW...\n",
                            "740                    https://briefingday.com/m/v4n3i4f3\n",
                            "277                     https://stevebryant.substack.com/\n",
                            "929     https://coronavirus.jhu.edu/testing/individual...\n",
                            "2734    https://www.washingtonpost.com/politics/2020/0...\n",
                            "317     https://en.wikipedia.org/wiki/Slab_City,_Calif...\n",
                            "382                           https://briefingday.com/fan\n",
                            "2202    https://www.morningbrew.com/daily/stories/2020...\n",
                            "2432                    https://jobs.lever.co/morningbrew\n",
                            "10      https://www.bbc.com/future/article/20200617-wh...\n",
                            "2764    https://www.nbcnews.com/news/us-news/coronavir...\n",
                            "Name: url, dtype: object"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw['url'].sample(20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    2303\n",
                            "1     696\n",
                            "Name: is_spam, dtype: int64"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw['is_spam'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Hay spam:  696\n",
                        "Que no son spam :  2303\n",
                        "(2999, 2)\n"
                    ]
                }
            ],
            "source": [
                "# Vamos a ver como esta nuestra variable objetivo en este caso es is_spam\n",
                "df_raw['is_spam'].value_counts()\n",
                "print(\"Hay spam: \",len(df_raw.loc[df_raw.is_spam==1]))\n",
                "print(\"Que no son spam : \",len(df_raw.loc[df_raw.is_spam==0]))\n",
                "print(df_raw.shape)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(2369, 2)"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Eliminar los duplicados\n",
                "\n",
                "df_raw = df_raw.drop_duplicates()\n",
                "df_raw = df_raw.reset_index(inplace = False)[['url','is_spam']]\n",
                "df_raw.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Empezamos el proceso de Limipieza de los datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": [
                "# colocar todos los textos en minusculas\n",
                "df_raw['url'] = df_raw['url'].str.lower()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['i', 'me', 'my', 'myself', 'we']\n",
                        "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to /home/gitpod/nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n",
                        "[nltk_data] Downloading package punkt to /home/gitpod/nltk_data...\n",
                        "[nltk_data]   Package punkt is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "nltk.download('stopwords')\n",
                "nltk.download('punkt')\n",
                "\n",
                "stopwords = nltk.corpus.stopwords.words('english')\n",
                "punctuation = string.punctuation\n",
                "\n",
                "print(stopwords[:5])\n",
                "print(punctuation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_aux = df_raw.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https briefingday us list manage com unsubscribe</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https www hvper com</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https briefingday com m v n i f</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https briefingday com n m commentform</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https briefingday com fan</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                url  is_spam\n",
                            "0  https briefingday us list manage com unsubscribe        1\n",
                            "1                              https www hvper com         1\n",
                            "2                  https briefingday com m v n i f         1\n",
                            "3             https briefingday com n m commentform        0\n",
                            "4                         https briefingday com fan        1"
                        ]
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "# Proceso de limpieza de datos\n",
                "\n",
                "limpieza = []\n",
                "\n",
                "for p in range(len(df_aux.url)):\n",
                "    desc = df_aux['url'][p]\n",
                "    \n",
                "    #savar la puntuacion\n",
                "    desc = re.sub('[^a-zA-Z]', ' ', desc)\n",
                "    \n",
                "    #borrar etiquetas especiales\n",
                "    desc=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",desc)\n",
                "    \n",
                "    #borrar digitos y caracteres especiales\n",
                "    desc=re.sub(\"(\\\\d|\\\\W)+\",\" \",desc)\n",
                "    \n",
                "    limpieza.append(desc)\n",
                "\n",
                "#assign the cleaned descriptions to the data frame\n",
                "df_aux['url'] = limpieza\n",
                "        \n",
                "df_aux.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "https          2336\n",
                            "the             354\n",
                            "html            296\n",
                            "news            274\n",
                            "a               252\n",
                            "us              248\n",
                            "of              173\n",
                            "coronavirus     172\n",
                            "e               150\n",
                            "org             146\n",
                            "c               136\n",
                            "article         131\n",
                            "b               124\n",
                            "and             113\n",
                            "morningbrew     105\n",
                            "story           105\n",
                            "nytimes         101\n",
                            "on              101\n",
                            "daily            99\n",
                            "d                98\n",
                            "stories          94\n",
                            "utm              90\n",
                            "youtube          89\n",
                            "v                89\n",
                            "trump            88\n",
                            "numlock          87\n",
                            "watch            86\n",
                            "f                78\n",
                            "new              76\n",
                            "p                69\n",
                            "world            68\n",
                            "substack         68\n",
                            "reuters          65\n",
                            "covid            63\n",
                            "s                62\n",
                            "index            61\n",
                            "briefingday      61\n",
                            "en               59\n",
                            "vox              59\n",
                            "articles         58\n",
                            "iduskbn          58\n",
                            "cnn              58\n",
                            "co               56\n",
                            "politics         56\n",
                            "cnbc             54\n",
                            "n                54\n",
                            "sunday           51\n",
                            "business         49\n",
                            "court            48\n",
                            "apnews           47\n",
                            "u                46\n",
                            "email            46\n",
                            "facebook         46\n",
                            "health           45\n",
                            "bbc              41\n",
                            "be               41\n",
                            "supreme          41\n",
                            "blog             40\n",
                            "are              40\n",
                            "medium           39\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 58,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_aux['url'].str.split(expand=True).stack().value_counts()[:60]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creamos una lista de stopwords\n",
                "stop_words = ['http','www','com','you','your','for','not','have','is','in','im','from','to','https','e','c','v','b','f','p']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def remove_stopwords(message):\n",
                "  if message is not None:\n",
                "    words = message.strip().split()\n",
                "    words_filtered = []\n",
                "    for word in words:\n",
                "      if word not in stop_words:\n",
                "        words_filtered.append(word) \n",
                "    result = \" \".join(words_filtered)         \n",
                "  else:\n",
                "    result = None\n",
                "\n",
                "  return result \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_aux['url']=df_aux['url'].apply(remove_stopwords)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>998</th>\n",
                            "      <td>fingeronthe app</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>24</th>\n",
                            "      <td>josefschulz uebergang</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>111</th>\n",
                            "      <td>cnn tech wirecard fraud tech accounting</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1765</th>\n",
                            "      <td>wsj articles shift plans go public year covid ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1193</th>\n",
                            "      <td>wtf us list manage unsubscribe</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>768</th>\n",
                            "      <td>cnbc new york new jersey connecticut impose da...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1558</th>\n",
                            "      <td>wsj articles fracking trailblazer chesapeake e...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1265</th>\n",
                            "      <td>theguardian society jun online harassment incr...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2123</th>\n",
                            "      <td>youtube watch n cp zpbmaq</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1867</th>\n",
                            "      <td>vox policy politics voxcare remdesivir price c...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                    url  is_spam\n",
                            "998                                     fingeronthe app        0\n",
                            "24                                josefschulz uebergang        0\n",
                            "111             cnn tech wirecard fraud tech accounting        0\n",
                            "1765  wsj articles shift plans go public year covid ...        0\n",
                            "1193                     wtf us list manage unsubscribe        1\n",
                            "768   cnbc new york new jersey connecticut impose da...        0\n",
                            "1558  wsj articles fracking trailblazer chesapeake e...        0\n",
                            "1265  theguardian society jun online harassment incr...        0\n",
                            "2123                          youtube watch n cp zpbmaq        0\n",
                            "1867  vox policy politics voxcare remdesivir price c...        0"
                        ]
                    },
                    "execution_count": 77,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_aux.sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "html           296\n",
                            "news           274\n",
                            "us             248\n",
                            "coronavirus    172\n",
                            "org            146\n",
                            "article        131\n",
                            "story          105\n",
                            "morningbrew    105\n",
                            "nytimes        101\n",
                            "daily           99\n",
                            "stories         94\n",
                            "utm             90\n",
                            "youtube         89\n",
                            "trump           88\n",
                            "numlock         87\n",
                            "watch           86\n",
                            "new             76\n",
                            "substack        68\n",
                            "world           68\n",
                            "reuters         65\n",
                            "covid           63\n",
                            "index           61\n",
                            "briefingday     61\n",
                            "vox             59\n",
                            "en              59\n",
                            "articles        58\n",
                            "cnn             58\n",
                            "iduskbn         58\n",
                            "politics        56\n",
                            "co              56\n",
                            "cnbc            54\n",
                            "n               54\n",
                            "sunday          51\n",
                            "business        49\n",
                            "court           48\n",
                            "apnews          47\n",
                            "email           46\n",
                            "u               46\n",
                            "facebook        46\n",
                            "health          45\n",
                            "supreme         41\n",
                            "bbc             41\n",
                            "blog            40\n",
                            "medium          39\n",
                            "black           39\n",
                            "npr             38\n",
                            "police          38\n",
                            "digg            37\n",
                            "campaign        37\n",
                            "cases           35\n",
                            "theverge        35\n",
                            "apple           35\n",
                            "theguardian     35\n",
                            "source          34\n",
                            "live            34\n",
                            "jun             32\n",
                            "tech            31\n",
                            "video           31\n",
                            "amazon          29\n",
                            "pandemic        29\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 78,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_aux['url'].str.split(expand=True).stack().value_counts()[:60]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esto es algo que estaba en el material de estudio para poder probar como funciona\n",
                "\n",
                "df['len_url'] = df['url'].apply(lambda x : len(x))\n",
                "df['contains_subscribe'] = df['url'].apply(lambda x : 1 if \"subscribe\" in x else 0)\n",
                "df['contains_hash'] = df['url'].apply(lambda x : 1 if \"#\" in x else 0)\n",
                "df['num_digits'] = df['url'].apply(lambda x : len(\"\".join(_ for _ in x if _.isdigit())) )\n",
                "df['non_https'] = df['url'].apply(lambda x : 1 if \"https\" in x else 0)\n",
                "df['num_words'] = df['url'].apply(lambda x : len(x.split(\"/\")))\n",
                "\n",
                "target = 'is_spam'\n",
                "features = [f for f in df.columns if f not in [\"url\", target]]\n",
                "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ahora que hemos limpiado nuestros datos\n",
                "# procedemos a hacer una copia con el dataset a trabajar en el final\n",
                "df = df_aux.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df['url']\n",
                "y = df['is_spam']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=121)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vectorizador\n",
                "vec = CountVectorizer(stop_words='english')\n",
                "X_train = vec.fit_transform(X_train).toarray()\n",
                "X_test = vec.transform(X_test).toarray()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 0]\n",
                        " ...\n",
                        " [0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 0]]\n"
                    ]
                }
            ],
            "source": [
                "print(X_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(1776, 4819)"
                        ]
                    },
                    "execution_count": 83,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(593, 4819)"
                        ]
                    },
                    "execution_count": 84,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_test.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['aa' 'aab' 'aaron' ... 'zulalimtm' 'zwift' 'zwn']\n"
                    ]
                }
            ],
            "source": [
                "print(vec.get_feature_names_out())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {},
            "outputs": [],
            "source": [
                "nb = MultinomialNB()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "MultinomialNB()"
                        ]
                    },
                    "execution_count": 90,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nb.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.956081081081081"
                        ]
                    },
                    "execution_count": 91,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nb.score(X_train,y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.9173693086003373"
                        ]
                    },
                    "execution_count": 92,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nb.score(X_test,y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.93      0.98      0.96       532\n",
                        "           1       0.68      0.38      0.48        61\n",
                        "\n",
                        "    accuracy                           0.92       593\n",
                        "   macro avg       0.80      0.68      0.72       593\n",
                        "weighted avg       0.91      0.92      0.91       593\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "predictions = nb.predict(X_test)\n",
                "print(classification_report(y_test, predictions))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Creando la Matriz\n",
                "\n",
                "message_vectorizer = CountVectorizer().fit_transform(df['url'])\n",
                "\n",
                "# Haciendo el split de los datos\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(message_vectorizer, df['is_spam'], test_size = 0.40, random_state = 121, shuffle = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "metadata": {},
            "outputs": [],
            "source": [
                "cl = svm.SVC(C=1.0, kernel='linear', degree=4, gamma='auto')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.94      0.98      0.96       847\n",
                        "           1       0.71      0.51      0.60       101\n",
                        "\n",
                        "    accuracy                           0.93       948\n",
                        "   macro avg       0.83      0.75      0.78       948\n",
                        "weighted avg       0.92      0.93      0.92       948\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "cl.fit(X_train, y_train)\n",
                "pred = cl.predict(X_test)\n",
                "print(classification_report(y_test, pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "metadata": {},
            "outputs": [],
            "source": [
                "pickle.dump(cl, open('../models/texto_NLP.pkl', 'wb'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Si queremos cargar el archivo guardado en la carpeta models\n",
                "\n",
                "load_model = pickle.load(open('../models/texto_NLP.pkl', 'rb'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(degree=4, gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(degree=4, gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "SVC(degree=4, gamma='auto', kernel='linear')"
                        ]
                    },
                    "execution_count": 109,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "load_model"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
